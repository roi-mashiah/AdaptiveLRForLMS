# AdaptiveLRForLMS
The convergence of the LMS (Least Mean Squares) method and its dependency on the step size parameter are crucial considerations in various applications. In this work, we investigate the effects of step size on LMS convergence in a source coding scenario. An algorithm for adaptive learning rate is suggested and examined in various scenarios. The proposed algorithm is described here:

- Every predefined block size, calculate the MSE vector based on the error vector.
- If a previous value for the MSE exists, compare the current error to the previous.
- Decide the new step size according to the difference as follows:
  o If the difference is less than ğ´ then we can increase the step size ğœ‡, by 1+ğº,0<ğº<1 to converge faster, if ğœ‡(1+ğº)<ğœ‡ğ‘šğ‘ğ‘¥
  o If the difference obeys ğ´<ğ‘‘<3ğ´, we are probably at some area close to a minimum which implies that we should decrease the current step size.
  o If ğ‘‘>3ğ´, we might be diverging so reduce the step size dramatically by a factor of ğº.
  o For any other case we stay with the previous step size
For more details reffer to the attached PDF.
